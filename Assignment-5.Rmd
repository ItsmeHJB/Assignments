---
title: "Assignment-5"
author: "ItsmeHJB"
date: "27/10/2021"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
```

# Assignment 5
## 1 - Expectation and variance in discrete random variable

Let $\alpha,\beta \in [0,1]$ with $\alpha + \beta \le 1$
X is supported on {0, 1, 5}

We could also say: $\Omega = \{0, 1, 5\}$

$\mathbb{P}(X=1)=\alpha$ and $\mathbb{P}(X=5)=\beta$

Also,
$\mathbb{P}(X \notin \{0, 1, 5\}) = 0$

### Probability mass function

Define the prob for each value of $\Omega$
\begin{equation}
  \mathbb{P}(X) =
  \begin{cases}
    1 - \alpha - \beta & x=0 \\
    \alpha & x=1 \\
    \beta & x=5 \\
    0 & \text{otherwise}
  \end{cases}
\end{equation}

$px(S) = (1 - \alpha - \beta) + \alpha$

$px(S) = 1 - \beta$

### Expectation

$\mathbb{E}(X) = (0 \cdot 1-\alpha-\beta) + (1 \cdot\alpha) + (5\cdot\beta) $

$\mathbb{E}(X) = \alpha + 5\beta $

### Variance

$Var(X) = \mathbb{E}(X^2) - [\mathbb{E}(X)]^2$

Work out E(X)^2
$\mathbb{E}(X^2) = (0^2 \cdot 1-\alpha-\beta) + (1^2 \cdot\alpha) + (5^2\cdot\beta) $

$\mathbb{E}(X^2) = 0 + \alpha + 25\beta$

$\mathbb{E}(X^2) = \alpha + 25\beta$

$Var(X) = \alpha + 25\beta - (5\beta+\alpha)^2$

$Var(X) = \alpha + 25\beta - (25\beta^2+10\beta\alpha+\alpha^2)$

## 2 - Simulating data with uniform distribution

```{r}
set.seed(0)

n<-1000

sample_X<-data.frame(U=runif(n)) %>%
  mutate(X=case_when(
    (0<=U)&(U<0.25)~1,
    (0.25<=U)&(U<0.5)~5,
    (0.5<=U)&(U<=1)~0)) %>%
  pull(X)

```

Simulating question 1 above, we can use the above code chunk to create i.i.d. variables

In this sample, both $\alpha$ and $\beta$ equal 0.25. If the value for U falls between 0 and 0.25, it is assigned 1, between 0.25 and 0.5, it is assigned 1. And finally if it is between 0.5 and 1, it is assigned 0.

Below is a function which can take alpha, beta and n as variables.
```{r}
sample_X_015 <- function(alpha, beta, n) {
  beta_start <- alpha+beta
  
  return(data.frame(u=runif(n)) %>%
    mutate(x=case_when(
      (0<=u)&(u<alpha) ~ 1,
      (alpha<=u)&(u<beta_start) ~ 5,
      (beta_start<=u)&(u<=1) ~ 0
    )) %>%
    pull(x)
  )
}
```

Setting up the probs and running the code
```{r}
alpha <- 0.5
beta <- 0.1
n <- 10000

# Vector of probs
PS <- c(1-alpha-beta, alpha, beta)

# Vector of outcomes
S <- c(0, 1, 5)

# Run the code
vals <- sample_X_015(alpha, beta, n)

# Expectation
ES <- sum(S * PS)
ES

# Average of values
mean(vals)

# Variance
var(vals)

```

We find the output of both the expectation and average to be extremely similar here. With the average floating around 1.0

Due to the large number of experiments, the sample slowly drifts closer to the expectation. If we increased n further, it would be closer still.

As we increase the value of beta, we find that the number of 5's increases and so the sample average tend upwards towards .
```{r}
beta_vals <- c(seq(0, 0.9, 0.01))
alpha <- 0.1
n <- 100

#temp <- data.frame(map(.x=data_x, ~sample_X_015(alpha,.x,n)))
#temp

vary_beta_sample<-data.frame(beta_vals)%>%
  mutate(rand_vars=map(.x=beta_vals,~sample_X_015(alpha, .x, n))) %>%
  mutate(sample_avg = map_dbl(.x=rand_vars,~mean(.x)))

head(vary_beta_sample)

graph <- vary_beta_sample %>%
  ggplot(aes(x=beta_vals, y=sample_avg)) + xlab("Beta")
graph + geom_line() + ylab("Sample avg")
```

## 3 - Gaussian distribution

Probability density function of the Gaussian random variable is:

$f\mu,\sigma (x) = \frac{1}{\sigma \sqrt{2\pi}} \cdot exp(-\frac{1}{2}(\frac{x-\mu}{\sigma})^2)$

The normal distribution functions all sit under the norm group:

 - dnorm - Probability Density func (Normal density)
 - pnorm - Cumulative Distribution func (Normal distribution)
 - qnorm - Quantile function of norm dist
 - rnorm - Normal random number generation

Plotting a Gaussian density func is as below:

```{r dnorm}
#ggplot(data=rename(hawksSmall,Species=Species),aes(x=Tail,colour=Species))+geom_density()+theme_bw()+xlab("Tail (mm)")+ylab("Density")

# Plot using ggplot
# Use stat_function to plot dnorm between range
ggplot(data.frame(x = c(-4, 6)), aes(x = x)) + 
  xlim(c(-4, 6)) + 
  stat_function(fun = dnorm, args = list(mean = 1, sd = sqrt(1)), aes(colour = "1")) + 
  stat_function(fun = dnorm, args = list(mean = 1, sd = sqrt(2)), aes(colour = "2")) +
  stat_function(fun = dnorm, args = list(mean = 1, sd = sqrt(3)), aes(colour = "3")) +
  labs(x = "X", y = "f(X)", 
       title = "Normal distribution function")
```

Plotting the cumulative distribution func:

```{r pnorm}
# Plot using ggplot
# Use stat_function to plot pnorm between range
ggplot(data.frame(x = c(-4, 6)), aes(x = x)) + 
  xlim(c(-4, 6)) + 
  stat_function(fun = pnorm, args = list(mean = 1, sd = sqrt(1)), aes(colour = "1")) + 
  stat_function(fun = pnorm, args = list(mean = 1, sd = sqrt(2)), aes(colour = "2")) +
  stat_function(fun = pnorm, args = list(mean = 1, sd = sqrt(3)), aes(colour = "3")) +
  labs(x = "X", y = "P(X < x)", 
       title = "Normal cumulative distribution function")
```

Plotting the normal quantile function

```{r}
# Plot using ggplot
# Use stat_function to plot qnorm between range
ggplot(data.frame(x = c(0, 1)), aes(x = x)) + 
  xlim(c(0, 1)) + 
  stat_function(fun = qnorm, args = list(mean = 1, sd = sqrt(1)), aes(colour = "1")) + 
  stat_function(fun = qnorm, args = list(mean = 1, sd = sqrt(2)), aes(colour = "2")) +
  stat_function(fun = qnorm, args = list(mean = 1, sd = sqrt(3)), aes(colour = "3")) +
  labs(x = "p", y = "Q(p)", 
       title = "Normal quantile function")
```


## Q4 - Binomial distribution and the central limit theorem

We can build a compute the probability mass function using dbinom as shown below. The value of x varies between 0 and 50, whilst the size, n, and the probability, p, remain the same at 50 and 7/10 respectfully.
```{r}
n <- 50
p <- 7/10

binom_df <- data.frame(x=0:50) %>%
  mutate(pmf=map_dbl(.x=x,~dbinom(.x, size=n, prob=p)))

head(binom_df, 3)
```

The same can be done for normal distributions using dnorm to produce a probability density function value.
```{r}
mu <- 50 * 0.7
sigma <- sqrt(50 * 0.7 * (1 - 0.7))

norm_df = data.frame(x=seq(0, 50, 0.01)) %>%
  mutate(pdf=dnorm(x, mean = mu, sd = sigma))

head(norm_df, 3)
```


Compare binomial probability mass function and gaussian probability density function
```{r}
gaussian_df <- norm_df

colors<-c("Gaussian pdf"="red", "Binomial pmf"="blue")
fill<-c("Gaussian pdf"="white", "Binomial pmf"="white")

ggplot()+labs(x="x",y="Probability")+theme_bw()+
  geom_line(data=gaussian_df,
  aes(x,y=pdf,color="Gaussian pdf"),size=2)+
  # create plot of Gaussian density
  geom_col(data=binom_df,
                  aes(x=x,y=pmf,color="Binomial pmf",fill="Binomial pmf"))+
  scale_color_manual(name = "", values=colors)+
  scale_fill_manual(name = "", values=fill)+
  xlim(c(20,50))

```

# Q5 - Exponential distribution

```{r}
my_cdf_exp <- function(x, lambda) {
  # Assume inputs are sanity checked
  
  #?
}
```

